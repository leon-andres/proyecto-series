---
title: "Modelos de la familia ARIMA"
---

```{r CargarObjetos}
#| echo: false

load('ObjetosDescriptiva.Rdata')

```

```{r Librerias}
#| echo: false
#| warnings: false
#| include: false


library(dplyr)
library(readxl)
library(readr)
library(plotly)
```

# Preparación de datos

## Partición 

Se realizará la partición de los datos en 80% para entrenamiento y 20% para prueba con el fin de ver la capacidad predictiva de los modelos propuestas que surjan por el proceso. Para la serie del Oro hay 249 observaciones en entrenamiento y 63 de prueba. En la serie de Hurtos hay 12844 para entrenamiento y 6422 para prueba.

Del análisis anterior se trabajará con las series diferenciadas porque son la manera más efectiva de disminuir la estructura de autocorrelación y eliminar la tendencia.

```{r Partición}
#| echo: false
# Oro
ntrain <- trunc(dim(DatosO)[1]*0.8)
OroTrain <- DatosO[1:ntrain,]
OroTest <- DatosO[(ntrain + 1): nrow(DatosO),]

# Hurtos
ntrain <- trunc(dim(DatosH)[1]*0.8)
HurtosTrain <- DatosH[1:ntrain,]
HurtosTest <-DatosH[(ntrain+1):nrow(DatosH),]
```

```{r ObjetosTS}
#| echo: false
# Oro
Oro <- ts(data = OroTrain$BC, start = c(1998,7), frequency = 12)
OroDiff <- diff(Oro)

# Hurtos
Hurtos <- ts(HurtosTrain$BC, start = c(2003,01), frequency = 365)
HurtosDiff <- diff(Oro)
```

# Selección del modelo

::: panel-tabset
## Oro

### Prueba de Dickey-Fuller aumentada

```{r adfOro}
#| echo: false
ar(OroDiff)
aTSA::adf.test(OroDiff,nlag = 3)
```

En todos los casos, los valores del estadístico ADF fueron altamente negativos y el p-valor resultó ser ≤ 0.01 en todos los rezagos evaluados. Dado que el p-valor es menor a 0.05, podemos rechazar la hipótesis nula de no estacionariedad. Esto indica que la serie diferenciada es estacionaria, lo que significa que no es necesario aplicar más diferenciaciones.

Con la confirmación de que la serie diferenciada es estacionaria, el siguiente paso es determinar los valores de $p$ y $q$ del modelo ARIMA. Para ello, se deben analizar las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF).

```{r}
#| echo: false
par(mfrow = c(1,2))
forecast::Acf(DiferenciaOrd, main = "ACF de la serie diferenciada")
forecast::Pacf(DiferenciaOrd, main = "PACF de la serie diferenciada")
```

Ambos gráficos mostraron una caída abrupta después del primer rezago, lo que sugiere que no hay una clara preferencia entre los términos autoregresivos (AR) o de media móvil (MA) por separado. Este comportamiento indica que el proceso podría tener características tanto de autoregresión como de media móvil. Por lo tanto, se optó por considerar modelos de tipo ARMA, que combinan ambos componentes. En particular, se evaluará el modelo ARMA(1, 1), un modelo que incluye un término autoregresivo de primer orden (AR(1)) y un término de media móvil de primer orden (MA(1)).

### Función de autocorrelación extendida

El análisis de la función de autocorrelación extendida (EACF) se utilizó para obtener una visión más detallada de las interacciones entre los componentes autoregresivos (AR) y de media móvil (MA) en la serie temporal diferenciada.

```{r}
#| echo: false
TSA::eacf(OroDiff)
```

El análisis EACF sugiere que se podrían considerar los siguientes modelos:

-   **MA(1)**

-   **ARMA(1,1)**

-   **ARMA(2,1)**

Estos modelos son opciones viables basadas en los resultados obtenidos.

### Auto.arima()

Para la identificación del modelo adecuado para la serie temporal diferenciada, se utilizó el paquete auto.arima() en R. Este procedimiento evalúa diferentes combinaciones de términos autoregresivos (AR) y de media móvil (MA), así como el orden de diferenciación, seleccionando el modelo con el mejor ajuste en función de diversos criterios de información.

```{r AutoArimaOro}
#| echo: false
forecast::auto.arima(OroDiff, seasonal = F, max.p = 2, max.q = 2, trace = T)
```

Durante la búsqueda inicial, el modelo ARIMA(0,0,1) con media no cero mostró el mejor valor de AICc, con un valor de -796.86, seguido de ARIMA(1,0,2) con media no cero, cuyo AIC fue de –796.42. Sin embargo, se re-ajustaron los modelos para obtener los resultados más precisos sin las aproximaciones iniciales. Como resultado, el modelo seleccionado fue ARIMA(0,0,1) con media no nula.Los coeficientes estimados son:

-   **ma1** = 0.1354

-   **s.e.** = 0.0668

El modelo ARMA(1,0), con AIC de -795.35, también fue considerado y se mantendrá en cuenta como alternativa.

### Comparación de modelos

En la sección de comparación de modelos, se analizaron tres modelos ARMA (MA(1), ARMA(1,2), y ARMA(1,0)) usando tres criterios de selección de modelo: AICc, BIC y HQIC. Los resultados obtenidos son los siguientes:

```{r OroCriterios}
#| echo: false
# Ajustar los modelos ARMA
models <- list(
  arima(OroDiff, order = c(1, 0, 1), include.mean = F),  # ARMA(1,1)
  arima(OroDiff, order = c(0, 0, 1), include.mean = T),  # ARMA(0,1)
  arima(OroDiff, order = c(2, 0, 1), include.mean = F),  # ARMA(2,1)
  arima(OroDiff, order = c(1, 0, 2), include.mean = F),  # ARMA(1,2)
  arima(OroDiff, order = c(1, 0, 2), include.mean = T)  # ARMA(1,2)
)

# Función para calcular AICc, BIC y HQIC
calc_criteria <- function(model) {
  k <- length(coef(model))  # Número de parámetros
  n <- length(OroDiff)  # Número de observaciones
  aic <- AIC(model)
  bic <- BIC(model)
  hqic <- aic + 2 * log(log(n)) * k  # Fórmula de HQIC
  
  # Calcular AICc
  aicc <- aic + (2 * k * (k + 1)) / (n - k - 1)
  
  return(c(AICc = aicc, BIC = bic, HQIC = hqic))
}

# Aplicar la función a cada modelo
criteria_values <- t(sapply(models, calc_criteria))

# Asignar nombres a las filas y columnas
colnames(criteria_values) <- c("AICc", "BIC", "HQIC")
rownames(criteria_values) <- c("ARMA(1,1)", "MA(1)*", "ARMA(2,1)", "ARMA(1,2)", "ARMA(1,2)*")

# Mostrar la tabla 3x3
criteria_values
```
Aunque el modelo MA(1) con media no cero es el que tiene el mejor desempeño en dos de los tres criterios (BIC y HQIC), el modelo ARMA(1,2) con media no cero y muestra una ligera ventaja en AICc. A pesar de esta diferencia, se optó por el ARMA(2,1) con media no cero, ya que resulta más interesante desde el punto de vista del modelado, ya que incorpora una componente autoregresiva (AR), lo cual proporciona una mayor capacidad explicativa en comparación con un modelo puramente aleatorio (MA).


## Hurtos

### Prueba de Dickey-Fuller aumentada

:::


# Estimación y diagnóstico


::: panel-tabset

## Oro


```{r OroARMA12}
#| echo: false
arma12 <- forecast::Arima(OroDiff, order = c(1, 0, 2), include.mean = T)
summary(arma12)
```
En consecuencia, el modelo ARMA(1,2)

$$Y_t = 0.8749Y_{t−1}−0.7719\epsilon_{t−1}−0.1781\epsilon_{t−2}+0.0086+\epsilon_t
$$

fue seleccionado para su posterior análisis y evaluación, considerando tanto los criterios estadísticos como la naturaleza del modelo autoregresivo.



Se generó un gráfico de los residuos del modelo ARMA(1,2) para evaluar su comportamiento.

```{r OroResids}
#| echo: false
res <- residuals(arma12)
plot(res, main = "Residuos vs. Tiempo", ylab = "Residuos", xlab = "Tiempo")

```


Los residuos muestran una distribución que oscila alrededor de cero, con una varianza aparentemente constante a lo largo del tiempo. Esto indica que no existen patrones sistemáticos en los residuos, lo que sugiere que el modelo captura adecuadamente la estructura temporal de la serie.

Sin embargo, se observan algunos picos en los residuos, los cuales podrían ser indicativos de valores atípicos o eventos inusuales en la serie temporal. A pesar de estos picos, la mayor parte de los residuos sigue comportándose de manera aleatoria, lo que respalda la idoneidad del modelo en términos generales.

### ACF y PACF de los residuales

Se generaron los gráficos de la ACF (Autocorrelación) y la PACF (Autocorrelación Parcial) de los residuos del modelo ARMA(2,1) para evaluar la independencia de los mismos.

```{r}
#| echo: false
par(mfrow = c(1,2))
acf(res, main = "ACF de los residuales", lag.max = 80)
pacf(res, main = "PACF de los residuales", lag.max = 80)
```

En ambos gráficos, los valores de autocorrelación se mantienen dentro de los límites de significancia establecidos, lo que indica que no existen correlaciones significativas a diferentes rezagos.

La ACF muestra que las autocorrelaciones se extinguen rápidamente, sugiriendo que no hay dependencias lineales no capturadas por el modelo. De manera similar, la PACF también presenta un comportamiento aleatorio, sin picos significativos, lo que refuerza la idea de que el modelo ARMA(2,1) ha capturado la estructura temporal de la serie de manera adecuada.

### Prueba de Ljung-Box

```{r}
#| echo: false
###  prueba Ljung_Box para 18 rezagos
Ljung_Box <- NULL
for(i in 1:18){
 Ljung_Box1 <- Box.test(res, lag = i, type="Ljung")$p.value
 Ljung_Box <- rbind(Ljung_Box, cbind(i,Ljung_Box1))
}
colnames(Ljung_Box) <- c("Rezago","p-valor");
cat(" \n \n")
cat("Prueba Ljung_Box Hip?tesis nula independencia \n \n")
Ljung_Box

par(mfrow=c(1,1))
plot(Ljung_Box, main="Prueba Ljung and Box \n H0: Independencia",ylim=c(0,1))
abline(h=0.05,col="red")
```

La prueba de Ljung-Box para los residuos del modelo ARMA(1,2) muestra valores de p significativamente grandes de 1 a 18 rezagos. Dado que los valores de p es mucho mayor que el umbral de 0.05, podemos concluir que no hay autocorrelación significativa en los residuos. Esto indica que el modelo ha logrado capturar adecuadamente la estructura temporal de los datos, y los residuos son consistentes con un proceso de ruido blanco.

### Pruebas CUSUM y CUSUMQ

Para evaluar la estabilidad de los coeficientes y la varianza de los errores en el modelo, se realizaron las pruebas CUSUM y CUSUM de cuadrados (CUSUMQ).

```{r}
#| echo: false
# Histograma de los residuos
cucuq <- function(x,nivel){ 
    
    #C0 <- 0.09506
    #x <- t(std.resids)[,n]
    
    A <- 0.948 # CONSTANTE PARA RECTAS DEL 95% EN LA PRUEBA CUSUM 
    # (independiente del tama?o de muestra ?)
    N <- length(x)
    K <- 0
    T <- 1:N
    
    
    cu <- cumsum(x)/sd(x)
    LS <- A*sqrt(N-K-1)+2*A*(T-K-1)/sqrt(N-K-1)
    LI <- -LS
    
    cu2 <- cumsum(x*x)/sum(x*x)
    LS2 <- nivel+(T-K-1)/(N-K-1)
    LI2 <- -nivel+(T-K-1)/(N-K-1)
    
    y <- cbind(cu,LS,LI)
    y2 <- cbind(cu2,LS2,LI2)
    
    par(mfrow=c(1,2))
    par(las=1)
    matplot(x=(1:N),y, xlab="tiempo", ylab= "CUSUM", type ="l" , col=c(1,2,2),lwd = 1,lend=2, lty=c(1,2,2))
    
    par(las=1)
    matplot(x=(1:N),y2, xlab="tiempo", ylab= "CUSUMQ", type ="l" , col=c(1,2,2),lwd = 1,lend=2, lty=c(1,2,2))
    
    #durbin.watson(x)
    #shapiro.test(x)
    #levene.test(x)
}
cucuq(res,0.09506)

```

-   **CUSUM:** La estadística se mantiene dentro de los límites de confianza en todo el período analizado, lo que indica estabilidad en los coeficientes del modelo.

-   **CUSUMQ:** Se observa una leve salida de la línea negra respecto a los límites de confianza en un punto, pero posteriormente regresa dentro de los límites, lo que sugiere que hubo una variación transitoria en la varianza de los errores, pero sin comprometer la estabilidad general del modelo.

Dado que el modelo está diseñado para predicción a corto plazo, esta fluctuación no representa un problema significativo. La rápida corrección observada indica que el modelo se adapta bien a las condiciones de los datos y que la varianza no presenta cambios estructurales permanentes.

### Evaluación de normalidad

```{r}
#| echo: false
#| # Histograma de los residuos
hist(res, main = "Histograma de los residuos", xlab = "Residuos", col = "lightblue", border = "black")

# Q-Q plot de los residuos
qqnorm(res)
qqline(res, col = "red")
#Test de normalidad
tseries::jarque.bera.test(res) # Se rechaza la hipótesis nula de normalidad, el modelo no es adecuado
```

El histograma de los residuos muestra que estos están sesgados a la derecha, lo cual indica una posible asimetría en los datos. El Q-Q plot también muestra que, aunque la mayoría de los puntos se alinean bien con la línea de referencia, en la cola superior se observa una ligera desviación, lo que sugiere una posible presencia de valores atípicos o una distribución no normal.

Además, el test de Jarque-Bera ofrece un valor de p de 9.992e-16, que es mucho menor que 0.05. Esto lleva a rechazar la hipótesis nula de que los residuos siguen una distribución normal, lo que indica que el modelo no cumple completamente con el supuesto de normalidad en los residuos.





## Hurtos

:::

# Capacidad predictiva

En esta sección se determinará la capacidad de generalización de los modelos; con los parámetros estimados se calcularán métricas en los valores predecidos sobre la muestra de prueba.

```{r OroARIMA}
#| echo: false

# Acá se usa la serie original y se hace la transf. y diff.
Oro <- ts(data = OroTrain$Pesos, start = c(1998,7), frequency = 12)
OroARIMA <- forecast::Arima(Oro,order = c(1,1,2), include.mean = TRUE, lambda = 0)
# Serie sobre el conjunto de prueba
OroT <- ts(data=OroTest$Pesos, start = c(2019,4), frequency = 12)
```




::: panel-tabset

## Oro


```{r OroMetricas}
#| echo: false

OroARIMA.eval <-forecast::Arima(OroT, model = OroARIMA)
Train <- forecast::accuracy(OroARIMA)
Test <- forecast::accuracy(OroARIMA.eval)

Metricas <- rbind(Train,Test)
rownames(Metricas) <- c('Entrenamiento','Prueba')
Metricas

```


## Hurtos

::: 

