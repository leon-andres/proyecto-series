---
title: "Modelos de la familia SARIMA"
---

```{r CargarObjetos}
#| echo: false

load('ObjetosDescriptiva.Rdata')

```

```{r Librerias}
#| echo: false
#| warnings: false
#| include: false


library(dplyr)
library(readxl)
library(readr)
library(plotly)
```

# Preparación de datos

## Partición 

Se realizará la partición de los datos en 80% para entrenamiento y 20% para prueba con el fin de ver la capacidad predictiva de los modelos propuestas que surjan por el proceso. Para la serie del Oro hay 249 observaciones en entrenamiento y 63 de prueba. En la serie de Hurtos hay 6422 para entrenamiento y 1606 para prueba.

Del análisis anterior se trabajará con las series diferenciadas porque son la manera más efectiva de disminuir la estructura de autocorrelación y eliminar la tendencia.

```{r Partición}
#| echo: false
# Oro
ntrain <- trunc(dim(DatosO)[1]*0.8)
OroTrain <- DatosO[1:ntrain,]
OroTest <- DatosO[(ntrain + 1): nrow(DatosO),]

# Hurtos
ntrain <- trunc(dim(DatosH)[1]*0.8)
HurtosTrain <- DatosH[1:ntrain,]
HurtosTest <-DatosH[(ntrain+1):nrow(DatosH),]
```

```{r ObjetosTS}
#| echo: false
# Oro
Oro <- ts(data = OroTrain$BC, start = c(1998,7), frequency = 12)
OroDiff <- diff(Oro)

# Hurtos
Hurtos <- ts(HurtosTrain$BC, start = c(2003,01), frequency = 365)
HurtosDiff <- diff(Hurtos)
```

# Selección del modelo

::: panel-tabset
## Oro

### Prueba de Dickey-Fuller aumentada

```{r adfOro}
#| echo: false
ar(OroDiff)
aTSA::adf.test(OroDiff,nlag = 3)
```

En todos los casos, los valores del estadístico ADF fueron altamente negativos y el p-valor resultó ser ≤ 0.01 en todos los rezagos evaluados. Dado que el p-valor es menor a 0.05, podemos rechazar la hipótesis nula de no estacionariedad. Esto indica que la serie diferenciada es estacionaria, lo que significa que no es necesario aplicar más diferenciaciones.

Con la confirmación de que la serie diferenciada es estacionaria, el siguiente paso es determinar los valores de $p$ y $q$ del modelo ARIMA. Para ello, se deben analizar las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF).

```{r}
#| echo: false
par(mfrow = c(1,2))
forecast::Acf(DiferenciaOrd, main = "ACF de la serie diferenciada")
forecast::Pacf(DiferenciaOrd, main = "PACF de la serie diferenciada")
```

Ambos gráficos mostraron una caída abrupta después del primer rezago, lo que sugiere que no hay una clara preferencia entre los términos autoregresivos (AR) o de media móvil (MA) por separado. Este comportamiento indica que el proceso podría tener características tanto de autoregresión como de media móvil. Por lo tanto, se optó por considerar modelos de tipo ARMA, que combinan ambos componentes. En particular, se evaluará el modelo ARMA(1, 1), un modelo que incluye un término autoregresivo de primer orden (AR(1)) y un término de media móvil de primer orden (MA(1)).

### Función de autocorrelación extendida

El análisis de la función de autocorrelación extendida (EACF) se utilizó para obtener una visión más detallada de las interacciones entre los componentes autoregresivos (AR) y de media móvil (MA) en la serie temporal diferenciada.

```{r}
#| echo: false
TSA::eacf(OroDiff)
```

El análisis EACF sugiere que se podrían considerar los siguientes modelos:

-   **MA(1)**

-   **ARMA(1,1)**

-   **ARMA(2,1)**

Estos modelos son opciones viables basadas en los resultados obtenidos.

### Auto.arima()

Para la identificación del modelo adecuado para la serie temporal diferenciada, se utilizó el paquete auto.arima() en R. Este procedimiento evalúa diferentes combinaciones de términos autoregresivos (AR) y de media móvil (MA), así como el orden de diferenciación, seleccionando el modelo con el mejor ajuste en función de diversos criterios de información.

```{r AutoArimaOro}
#| echo: false
forecast::auto.arima(OroDiff, seasonal = F, max.p = 2, max.q = 2, trace = T)
```

Durante la búsqueda inicial, el modelo ARIMA(0,0,1) con media no cero mostró el mejor valor de AICc, con un valor de -796.86, seguido de ARIMA(1,0,2) con media no cero, cuyo AIC fue de –796.42. Sin embargo, se re-ajustaron los modelos para obtener los resultados más precisos sin las aproximaciones iniciales. Como resultado, el modelo seleccionado fue ARIMA(0,0,1) con media no nula.Los coeficientes estimados son:

-   **ma1** = 0.1354

-   **s.e.** = 0.0668

El modelo ARMA(1,0), con AIC de -795.35, también fue considerado y se mantendrá en cuenta como alternativa.

### Comparación de modelos

En la sección de comparación de modelos, se analizaron tres modelos ARMA (MA(1), ARMA(1,2), y ARMA(1,0)) usando tres criterios de selección de modelo: AICc, BIC y HQIC. Los resultados obtenidos son los siguientes:

```{r OroCriterios}
#| echo: false
# Ajustar los modelos ARMA
models <- list(
  arima(OroDiff, order = c(1, 0, 1), include.mean = F),  # ARMA(1,1)
  arima(OroDiff, order = c(0, 0, 1), include.mean = T),  # ARMA(0,1)
  arima(OroDiff, order = c(2, 0, 1), include.mean = F),  # ARMA(2,1)
  arima(OroDiff, order = c(1, 0, 2), include.mean = F),  # ARMA(1,2)
  arima(OroDiff, order = c(1, 0, 2), include.mean = T)  # ARMA(1,2)
)

# Función para calcular AICc, BIC y HQIC
calc_criteria <- function(model) {
  k <- length(coef(model))  # Número de parámetros
  n <- length(OroDiff)  # Número de observaciones
  aic <- AIC(model)
  bic <- BIC(model)
  hqic <- aic + 2 * log(log(n)) * k  # Fórmula de HQIC
  
  # Calcular AICc
  aicc <- aic + (2 * k * (k + 1)) / (n - k - 1)
  
  return(c(AICc = aicc, BIC = bic, HQIC = hqic))
}

# Aplicar la función a cada modelo
criteria_values <- t(sapply(models, calc_criteria))

# Asignar nombres a las filas y columnas
colnames(criteria_values) <- c("AICc", "BIC", "HQIC")
rownames(criteria_values) <- c("ARMA(1,1)", "MA(1)*", "ARMA(2,1)", "ARMA(1,2)", "ARMA(1,2)*")

# Mostrar la tabla 3x3
criteria_values
```
Aunque el modelo MA(1) con media no cero es el que tiene el mejor desempeño en dos de los tres criterios (BIC y HQIC), el modelo ARMA(1,2) con media no cero y muestra una ligera ventaja en AICc. A pesar de esta diferencia, se optó por el ARMA(2,1) con media no cero, ya que resulta más interesante desde el punto de vista del modelado, ya que incorpora una componente autoregresiva (AR), lo cual proporciona una mayor capacidad explicativa en comparación con un modelo puramente aleatorio (MA).


## Hurtos

### Prueba de Dickey-Fuller aumentada

```{r}
#| echo: false

# ar(HurtosDiff)
aTSA::adf.test(HurtosDiff, nlag = 3)
```

No hay presencia de tendencia estocástica por raíz unitaria, se trabajará con la serie en primera diferencia ordinaria.

### Estructura de autocorrelación

Se determinarán los rezagos más significativos para la ***ACF*** y ***PACF***

```{r HurtosAcfPacf}
#| echo: false
par(mfrow=c(1,2))
forecast::Acf(HurtosDiff,80)
forecast::Pacf(HurtosDiff,80)
```

Como lo habíamos visto en el periodograma, hay una correlación significativa cada 7 días.
Por lo tanto con la prueba **nsdiffs()** se determina formalmente la presencia de raíz unitaria estacional. 

Se realiza la diferencia ordinaria estacional y se obtiene lo siguiente


```{r Hurtos-nsdiff}
#| echo: false

# s <- forecast::nsdiffs(HurtosDiff, test = 'ch')

HurtosDiffS <- diff(HurtosDiff,lag = 7, differences = 1)
par(mfrow=c(1,2))
forecast::Acf(HurtosDiffS,80)
forecast::Pacf(HurtosDiffS,80)



```

A lo más se podría considerar un modelo **SARIMA(6,1,1)X(11,1,1)[7]**. Sin embargo al considerar este modelo hubo problemas en la proceso de optimización y por lo tanto no se logró estimar.

```{r}
#| echo: false

forecast::auto.arima(Hurtos)
```


Note que el ajuste automático no es efectivo pues no tiene en cuenta la componente estacional!.

:::


# Estimación y diagnóstico


::: panel-tabset

## Oro


```{r OroARMA12}
#| echo: false
arma12 <- forecast::Arima(OroDiff, order = c(1, 0, 2), include.mean = T)
summary(arma12)
```
En consecuencia, el modelo ARMA(1,2)

$$Y_t = 0.8749Y_{t−1}−0.7719\epsilon_{t−1}−0.1781\epsilon_{t−2}+0.0086+\epsilon_t
$$

fue seleccionado para su posterior análisis y evaluación, considerando tanto los criterios estadísticos como la naturaleza del modelo autoregresivo.



Se generó un gráfico de los residuos del modelo ARMA(1,2) para evaluar su comportamiento.

```{r OroResids}
#| echo: false
res <- residuals(arma12)
plot(res, main = "Residuos vs. Tiempo", ylab = "Residuos", xlab = "Tiempo")

```


Los residuos muestran una distribución que oscila alrededor de cero, con una varianza aparentemente constante a lo largo del tiempo. Esto indica que no existen patrones sistemáticos en los residuos, lo que sugiere que el modelo captura adecuadamente la estructura temporal de la serie.

Sin embargo, se observan algunos picos en los residuos, los cuales podrían ser indicativos de valores atípicos o eventos inusuales en la serie temporal. A pesar de estos picos, la mayor parte de los residuos sigue comportándose de manera aleatoria, lo que respalda la idoneidad del modelo en términos generales.

### ACF y PACF de los residuales

Se generaron los gráficos de la ACF (Autocorrelación) y la PACF (Autocorrelación Parcial) de los residuos del modelo ARMA(2,1) para evaluar la independencia de los mismos.

```{r}
#| echo: false
par(mfrow = c(1,2))
acf(res, main = "ACF de los residuales", lag.max = 80)
pacf(res, main = "PACF de los residuales", lag.max = 80)
```

En ambos gráficos, los valores de autocorrelación se mantienen dentro de los límites de significancia establecidos, lo que indica que no existen correlaciones significativas a diferentes rezagos.

La ACF muestra que las autocorrelaciones se extinguen rápidamente, sugiriendo que no hay dependencias lineales no capturadas por el modelo. De manera similar, la PACF también presenta un comportamiento aleatorio, sin picos significativos, lo que refuerza la idea de que el modelo ARMA(2,1) ha capturado la estructura temporal de la serie de manera adecuada.

### Prueba de Ljung-Box

```{r}
#| echo: false
###  prueba Ljung_Box para 18 rezagos
Ljung_Box <- NULL
for(i in 1:18){
 Ljung_Box1 <- Box.test(res, lag = i, type="Ljung")$p.value
 Ljung_Box <- rbind(Ljung_Box, cbind(i,Ljung_Box1))
}
colnames(Ljung_Box) <- c("Rezago","p-valor");
cat(" \n \n")
cat("Prueba Ljung_Box Hip?tesis nula independencia \n \n")
# Ljung_Box

par(mfrow=c(1,1))
plot(Ljung_Box, main="Prueba Ljung and Box \n H0: Independencia",ylim=c(0,1))
abline(h=0.05,col="red")
```

La prueba de Ljung-Box para los residuos del modelo ARMA(1,2) muestra valores de p significativamente grandes de 1 a 18 rezagos. Dado que los valores de p es mucho mayor que el umbral de 0.05, podemos concluir que no hay autocorrelación significativa en los residuos. Esto indica que el modelo ha logrado capturar adecuadamente la estructura temporal de los datos, y los residuos son consistentes con un proceso de ruido blanco.

### Pruebas CUSUM y CUSUMQ

Para evaluar la estabilidad de los coeficientes y la varianza de los errores en el modelo, se realizaron las pruebas CUSUM y CUSUM de cuadrados (CUSUMQ).

```{r}
#| echo: false
# Histograma de los residuos
cucuq <- function(x,nivel){ 
    
    #C0 <- 0.09506
    #x <- t(std.resids)[,n]
    
    A <- 0.948 # CONSTANTE PARA RECTAS DEL 95% EN LA PRUEBA CUSUM 
    # (independiente del tama?o de muestra ?)
    N <- length(x)
    K <- 0
    T <- 1:N
    
    
    cu <- cumsum(x)/sd(x)
    LS <- A*sqrt(N-K-1)+2*A*(T-K-1)/sqrt(N-K-1)
    LI <- -LS
    
    cu2 <- cumsum(x*x)/sum(x*x)
    LS2 <- nivel+(T-K-1)/(N-K-1)
    LI2 <- -nivel+(T-K-1)/(N-K-1)
    
    y <- cbind(cu,LS,LI)
    y2 <- cbind(cu2,LS2,LI2)
    
    par(mfrow=c(1,2))
    par(las=1)
    matplot(x=(1:N),y, xlab="tiempo", ylab= "CUSUM", type ="l" , col=c(1,2,2),lwd = 1,lend=2, lty=c(1,2,2))
    
    par(las=1)
    matplot(x=(1:N),y2, xlab="tiempo", ylab= "CUSUMQ", type ="l" , col=c(1,2,2),lwd = 1,lend=2, lty=c(1,2,2))
    
    #durbin.watson(x)
    #shapiro.test(x)
    #levene.test(x)
}
cucuq(res,0.09506)

```

-   **CUSUM:** La estadística se mantiene dentro de los límites de confianza en todo el período analizado, lo que indica estabilidad en los coeficientes del modelo.

-   **CUSUMQ:** Se observa una leve salida de la línea negra respecto a los límites de confianza en un punto, pero posteriormente regresa dentro de los límites, lo que sugiere que hubo una variación transitoria en la varianza de los errores, pero sin comprometer la estabilidad general del modelo.

Dado que el modelo está diseñado para predicción a corto plazo, esta fluctuación no representa un problema significativo. La rápida corrección observada indica que el modelo se adapta bien a las condiciones de los datos y que la varianza no presenta cambios estructurales permanentes.

### Evaluación de normalidad

```{r}
#| echo: false
#| # Histograma de los residuos
hist(res, main = "Histograma de los residuos", xlab = "Residuos", col = "lightblue", border = "black")

# Q-Q plot de los residuos
qqnorm(res)
qqline(res, col = "red")
#Test de normalidad
tseries::jarque.bera.test(res) # Se rechaza la hipótesis nula de normalidad, el modelo no es adecuado
```

El histograma de los residuos muestra que estos están sesgados a la derecha, lo cual indica una posible asimetría en los datos. El Q-Q plot también muestra que, aunque la mayoría de los puntos se alinean bien con la línea de referencia, en la cola superior se observa una ligera desviación, lo que sugiere una posible presencia de valores atípicos o una distribución no normal.

Además, el test de Jarque-Bera ofrece un valor de p de 9.992e-16, que es mucho menor que 0.05. Esto lleva a rechazar la hipótesis nula de que los residuos siguen una distribución normal, lo que indica que el modelo no cumple completamente con el supuesto de normalidad en los residuos.





## Hurtos

Con base en las funciones de autocorrelación se decide optar por el siguiente modelo.

```{r}
#| echo: false

# p max 6 , q= max6, P=11, Q=1
# 

# auto.arima(HurtosDiffS, d = 0, D = 0, max.p = 6, max.q = 6, max.P = 11, max.Q = 1)
# auto.arima(Hurtos, max.d = 1, max.D = 1, max.p = 6, max.q = 6, max.P = 11, max.Q = 1, seasonal.test = 'ch')


# modelo <- auto.arima(Hurtos)

# modelo <- forecast::Arima(Hurtos, c(6, 1, 6),seasonal = list(order = c(1, 1, 1), period = 7),lambda = 0.5090909)

# NO da nas


# modelo <- forecast::Arima(Hurtos,
#                           c(6, 1, 3),
#                           seasonal = list(order = c(1, 1, 1), period = 7),
#                           lambda = 0.5090909)


# segundo
modelo <- forecast::Arima(Hurtos,
                c(6, 1, 2),
                seasonal = list(order = c(2, 1, 1), period = 7),
                lambda = 0.5090909)

summary(modelo)
# Tercero
```


### ACF y PACF de los residuales

```{r}
#| echo: false

resHurtos <- residuals(modelo)
par(mfrow=c(1,2))
forecast::Acf(resHurtos, 80)
forecast::Pacf(resHurtos,80)
```




### Prueba de Ljung-Box

```{r}
#| echo: false
###  prueba Ljung_Box para 80 rezagos
Ljung_Box <- NULL
for(i in 1:80){
 Ljung_Box1 <- Box.test(resHurtos, lag = i, type="Ljung")$p.value
 Ljung_Box <- rbind(Ljung_Box, cbind(i,Ljung_Box1))
}
colnames(Ljung_Box) <- c("Rezago","p-valor");
cat(" \n \n")
cat("Prueba Ljung_Box Hip?tesis nula independencia \n \n")
# Ljung_Box

par(mfrow=c(1,1))
plot(Ljung_Box, main="Prueba Ljung and Box \n H0: Independencia",ylim=c(0,1))
abline(h=0.05,col="red")
```





### Pruebas CUSUM y CUSUMQ

```{r}
#| echo: false

cucuq(resHurtos, 0.05190)
```

No hay cambios estructurales en los coeficientes del modelo ni parece haber problemas de heterocedasticidad.

### Evaluación de normalidad


```{r}
#| echo: false
#| # Histograma de los residuos
hist(resHurtos, main = "Histograma de los residuos", xlab = "Residuos", col = "lightblue", border = "black")

# Q-Q plot de los residuos
qqnorm(resHurtos)
qqline(resHurtos, col = "red")
#Test de normalidad
tseries::jarque.bera.test(resHurtos) # Se rechaza la hipótesis nula de normalidad, el modelo no es adecuado
```
Es claro que los residuales no siguen una distribución normal porque presenta colas pesadas.


:::

# Detección y Corrección de Outliers

::: panel-tabset

## Oro

En la modelación de la serie temporal, se realizó un análisis de los residuos con el fin de identificar la presencia de valores atípicos (outliers). Estos valores extremos pueden distorsionar la estimación de los parámetros del modelo y afectar la precisión de las predicciones. Para su detección, se utilizó un criterio basado en la influencia de los valores atípicos en los residuos, considerando un umbral de significancia de 3 desviaciones estándar.


```{r}
#| echo: false

# Extraer coeficientes del modelo ARMA(1,2)
coef = tsoutliers::coefs2poly(arma12)

# Obtener residuos del modelo
res <- residuals(arma12)

# Detectar outliers en los residuos
outliers = tsoutliers::locate.outliers(res, coef, cval=3)
outliers

# Crear variables indicadoras de los outliers
xreg_outliers = tsoutliers::outliers.effects(outliers, length(res))

# Ajustar de nuevo el modelo ARMA(1,2) con los outliers corregidos
arma12 = update(arma12, xreg = xreg_outliers)

# xreg_outliersF <- rbind(c(0,0),xreg_outliers)
# arma12F <- Arima(oro, order = c(1, 1, 2), include.mean = F, lambda = 0, xreg = xreg_outliersF)


```

Los resultados indicaron la presencia de outliers en ciertos períodos, lo que sugiere la existencia de eventos anómalos que impactaron la serie. Para corregir este efecto, se incluyeron variables indicadoras que capturan la influencia de estos valores atípicos, permitiendo que el modelo los absorba en lugar de afectar la estructura general de la serie.

```{r}
#| echo: false

summary(arma12)
```


Finalmente, se obtiene el modelo ARMA(1,2) corregido como

$$
\begin{aligned}
Y_t &= 0.0075 + 
0.8569Y_{t−1}+
\epsilon_t−
0.7749\epsilon_{t−1}−
0.2251\epsilon_{t−2}+ \\
&\quad 0.1258I_{16,t}+
0.1656I_{31,t} +
0.1183I_{95,t}+
0.1932I_{128,t} - \\
&\quad 0.0974I_{222,t}
\end{aligned}
$$



Se verifican las cartas **CUSUM Y CUSUMQ** para ver si hay mejoría en los residuales del modelo corregido por outliers.

```{r}
#| echo: false

cucuq(residuals(arma12),0.11848)
par(mar=c(2.5,2.5,2,1))
tsdiag(arma12)

```
El modelo ya no presenta efecto de heterocedasticidad!.



## Hurtos



```{r}
#| echo: false

# Extraer coeficientes del modelo de Hurtos
coefHurtos = tsoutliers::coefs2poly(modelo)

# Obtener residuos del modelo
resHurtos <- residuals(modelo)

# Detectar outliers en los residuos
outliersHurtos = tsoutliers::locate.outliers(resHurtos, coefHurtos, cval=3)
table(outliersHurtos$type)

# Crear variables indicadoras de los outliers

# xreg_outliersHurtos = tsoutliers::outliers.effects(outliersHurtos, length(resHurtos))

# Ajustar de nuevo el modelo con los outliers corregidos

# modelo = update(modelo, xreg = xreg_outliersHurtos)


```
Los outliers más frecuentes son de cambio de nivel(**LS**), aditivos(**A0**) y de cambio temporal(**TC**). Sin embargo no se pudo re estimar el modelo con las variables para los outliers; posiblemente por multicolinealidad.

```{r}
#| echo: false
par(mar=c(2.5,2.5,2,1))
tsdiag(modelo,gof.lag = 80)
```
Hay presencia de outliers. No hay autocorrelación en los residuales hasta el rezago 80!.

:::




# Capacidad predictiva

En esta sección se determinará la capacidad de generalización de los modelos; con los parámetros estimados se calcularán métricas en los valores predecidos sobre la muestra de prueba.

::: panel-tabset

## Oro

```{r OroARIMA}
#| echo: false

# Acá se usa la serie original y se hace la transf. y diff.
Oro <- ts(data = OroTrain$Pesos, start = c(1998,7), frequency = 12)
OroARIMA <- forecast::Arima(Oro,order = c(1,1,2), include.mean = TRUE, lambda = 0)
# Serie sobre el conjunto de prueba
OroT <- ts(data=OroTest$Pesos, start = c(2019,4), frequency = 12)
```



```{r OroMetricas}
#| echo: false

OroARIMA.eval <-forecast::Arima(OroT, model = OroARIMA)
Train <- forecast::accuracy(OroARIMA)
Test <- forecast::accuracy(OroARIMA.eval)

Metricas <- rbind(Train,Test)
rownames(Metricas) <- c('Entrenamiento','Prueba')
Metricas





```


## Hurtos



```{r HurtosSARIMA}
#| echo: false

# Acá se usa la serie original y se hace la transf. y diff.

# Serie sobre el conjunto de prueba
HurtosT <- ts(data=HurtosTest$Cantidad, start = c(2019,4), frequency = 365)
```



```{r HurtosMetricas}
#| echo: false

HurtosSARIMA.eval <-forecast::Arima(HurtosT, model = modelo)
Train <- forecast::accuracy(modelo)
Test <- forecast::accuracy(HurtosSARIMA.eval)

Metricas <- rbind(Train,Test)
rownames(Metricas) <- c('Entrenamiento','Prueba')
Metricas


```


:::


# Predicción


::: panel-tabset

## Oro

Se realizó un pronóstico a un horizonte de 12 periodos (un año), utilizando el modelo ARMA(1,0,2) ajustado a la serie estacionaria. A continuación, se presenta el gráfico del pronóstico obtenido.


```{r}
#| echo: false
library(forecast)
newxreg <- matrix(0, nrow = 12, ncol = ncol(xreg_outliers))
colnames(newxreg) <- colnames(xreg_outliers)
pred <- forecast::forecast(arma12, h = 12, xreg = newxreg)
plot(pred)
```

El gráfico muestra que las predicciones tienden a la media de la serie, lo cual es esperado en modelos ARMA aplicados a series estacionarias. La banda de confianza se amplía con el horizonte de predicción, reflejando mayor incertidumbre.

Este resultado sugiere que el modelo captura bien la estructura de corto plazo, pero puede requerir ajustes para pronósticos de más largo plazo.

Si la serie original representa la evolución del precio del oro para regalías en Colombia, entonces su transformación logarítmica mide la tasa de crecimiento relativa del precio a lo largo del tiempo. Esto permite estabilizar la varianza y facilita la modelación de cambios proporcionales en lugar de valores absolutos.


```{r}
#| echo: false
#| warning: false
newxreg <- matrix(0, nrow = 64, ncol = ncol(xreg_outliers))
xreg_outliersF <- rbind(xreg_outliers,newxreg)


oro <- ts(DatosO[2], start=c(1998,7), end = c(2024,6), frequency = 12)

modeloOro <- Arima(oro, order = c(1, 1, 2), seasonal = list(order=c(0,1,1),period=12), include.drift = T, lambda = 0, xreg = xreg_outliersF)


newxreg <- matrix(0, nrow = 12, ncol = ncol(xreg_outliers))
s <- forecast::forecast(modeloOro,h=12, xreg=newxreg)

fitted_time   <- zoo::as.Date(zoo::as.yearmon(time(s$fitted)))
forecast_time <- zoo::as.Date(zoo::as.yearmon(time(s$mean)))

# Extraemos cada serie numérica
fitted_vals   <- as.numeric(s$fitted)
mean_vals     <- as.numeric(s$mean)
lower_80      <- as.numeric(s$lower[,1])
lower_95      <- as.numeric(s$lower[,2])
upper_80      <- as.numeric(s$upper[,1])
upper_95      <- as.numeric(s$upper[,2])

# Construimos la gráfica con plotly
fig <- plot_ly() %>%
  
  # 1) Valores ajustados (fitted) del modelo
  add_trace(
    x = fitted_time,
    y = fitted_vals,
    type = 'scatter',
    mode = 'lines',
    name = 'Ajustados'
  ) %>%
  
  # 2) Pronóstico (mean)
  add_trace(
    x = forecast_time,
    y = mean_vals,
    type = 'scatter',
    mode = 'lines',
    name = 'Pronóstico'
  ) %>%
  
  # 3) Intervalo de confianza al 95%
  add_ribbons(
    x = forecast_time,
    ymin = lower_95,
    ymax = upper_95,
    name = 'IC 95%',
    # fillcolor y line.color los puedes ajustar como gustes;
    # aquí se deja un ejemplo de transparencia para ver el pronóstico detrás
    fillcolor = 'rgba(7, 164, 181, 0.2)', 
    line = list(color = 'rgba(7, 164, 181, 0.2)')
  ) %>%
  
  # 4) Intervalo de confianza al 80%
  add_ribbons(
    x = forecast_time,
    ymin = lower_80,
    ymax = upper_80,
    name = 'IC 80%',
    fillcolor = 'rgba(7, 164, 181, 0.4)', 
    line = list(color = 'rgba(7, 164, 181, 0.4)')
  ) %>%
  
  layout(
    title = 'Valores Ajustados y Pronóstico con Intervalos de Confianza',
    xaxis = list(title = 'Fecha'),
    yaxis = list(title = 'Valor')
  )

fig
```

El modelo sigue la tendencia creciente de la serie, aunque la amplitud del intervalo de confianza aumenta con el horizonte de pronóstico, lo que sugiere mayor incertidumbre en las proyecciones a largo plazo.

Los valores siguen una tendencia creciente. El precio del oro para regalías en Colombia presenta un crecimiento sostenido en el horizonte de pronóstico.




## Hurtos

```{r}
#| echo: false
#| warning: false

# Crear la serie temporal con frecuencia diaria
HurtosF <- ts(DatosH$Cantidad, start = c(2003, 1), frequency = 365)

# Ajustar el modelo ARIMA estacional
modeloHurtos <- forecast::Arima(
  y = HurtosF, 
  order = c(6, 1, 2), 
  seasonal = list(order = c(2, 1, 1), period = 7), 
  lambda = 0.5090909
)



# Generar el pronóstico
s <- forecast::forecast(modeloHurtos, h = 7)

# Extraer fecha de inicio de la serie temporal
fecha_inicio <- as.Date("2003-01-01")
# Convertir fechas de fitted y forecast
fitted_time   <- seq(from = fecha_inicio, by = "day", length.out = length(s$fitted))
forecast_time <- seq(from = tail(fitted_time, 1) + 9, by = "day", length.out = length(s$mean))
# Extraer valores de fitted y forecast
fitted_vals   <- as.numeric(s$fitted)
mean_vals     <- as.numeric(s$mean)
lower_80      <- as.numeric(s$lower[, 1])
lower_95      <- as.numeric(s$lower[, 2])
upper_80      <- as.numeric(s$upper[, 1])
upper_95      <- as.numeric(s$upper[, 2])
# Construcción del gráfico interactivo con predicciones
fig <- plot_ly() %>%
# Datos históricos
add_trace(
data = DatosH,
x = ~Fecha,
y = ~Cantidad,
type = 'scatter',
mode = 'lines',
line = list(color = 'purple'),
name = 'Histórico'
) %>%
# Valores ajustados del modelo (fitted)
add_trace(
x = fitted_time,
y = fitted_vals,
type = 'scatter',
mode = 'lines',
line = list(color = 'green'),
name = 'Ajustados'
) %>%
# Línea de predicción
add_trace(
x = forecast_time,
y = mean_vals,
type = 'scatter',
mode = 'lines',
line = list(color = 'blue', dash = 'dot'),
name = 'Predicción'
) %>%
# Banda de intervalo de confianza al 95%
add_ribbons(
x = forecast_time,
ymin = lower_95,
ymax = upper_95,
name = 'IC 95%',
fillcolor = 'rgba(7, 164, 181, 0.2)',
line = list(color = 'rgba(7, 164, 181, 0.2)'),
hoverinfo = "text",
hovertext = paste0("Límite Inferior 95%: ", round(lower_95, 2),
"<br>Límite Superior 95%: ", round(upper_95, 2))
) %>%
# Banda de intervalo de confianza al 80%
add_ribbons(
x = forecast_time,
ymin = lower_80,
ymax = upper_80,
name = 'IC 80%',
fillcolor = 'rgba(7, 164, 181, 0.4)',
line = list(color = 'rgba(7, 164, 181, 0.4)'),
hoverinfo = "text",
hovertext = paste0("Límite Inferior 80%: ", round(lower_80, 2),
"<br>Límite Superior 80%: ", round(upper_80, 2))
) %>%
layout(
title = "Vehículos hurtados en Bogotá",
xaxis = list(
title = "Fecha",
rangeselector = list( # Botones de zoom rápido
buttons = list(
list(count = 1, label = "1m", step = "month", stepmode = "backward"),
list(count = 6, label = "6m", step = "month", stepmode = "backward"),
list(count = 1, label = "1y", step = "year", stepmode = "backward"),
list(step = "all")
)
),
rangeslider = list(visible = TRUE) # Agregar slider interactivo
),
yaxis = list(title = "Total Hurtos"),
hovermode = "x"
)
# Mostrar la figura
fig
```

Se observa que las predicciones tienden a la media del último mes (Diciembre de 2024); debido a la formulación del modelo. El horizonte de pronóstico es conservador (7 días) y esto asegura que la estimación por intervalo sea positiva.